{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc73066f-0e3e-41db-900f-bd5e94375e8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog = 'genesis_workbench'\n",
    "schema = 'dev_mmt_core_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "341137dd-bcfb-4906-aa51-e53bfe7a606f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"USE CATALOG {catalog}\")\n",
    "\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {schema}\")\n",
    "\n",
    "spark.sql(f\"USE SCHEMA {schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfedd957-c198-42cb-b072-72c513948b15",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{\"model_description_url\":{\"format\":{\"preset\":\"string-preset-url\"}}}},\"syncTimestamp\":1753127390414}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.table('genesis_workbench.dev_mmt_core_test.models'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9670e2c-c1b6-40f0-8c67-e5df88ffadc7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "models"
    }
   },
   "outputs": [],
   "source": [
    "# https://adb-830292400663869.9.azuredatabricks.net/jobs/847599598308030/runs/401215867480352?o=830292400663869\n",
    "\n",
    "spark.sql(\"DROP TABLE IF EXISTS models\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE models (\n",
    "    model_id BIGINT GENERATED ALWAYS AS IDENTITY,          \n",
    "    model_name STRING,\n",
    "    model_display_name STRING,\n",
    "    model_source_version STRING,\n",
    "    model_origin STRING, --uc, huggingface, pypi, bionemo, etc\n",
    "    model_description_url STRING, --website to find more details about model\n",
    "    model_category STRING, -- feature to which model is mapped\n",
    "    model_uc_name STRING,\n",
    "    model_uc_version STRING,\n",
    "    model_owner STRING,\n",
    "    model_added_by STRING,\n",
    "    model_added_date TIMESTAMP,    \n",
    "    model_input_schema STRING,\n",
    "    model_output_schema STRING,\n",
    "    model_params_schema STRING,\n",
    "    is_model_deployed BOOLEAN,\n",
    "    deployment_ids STRING,\n",
    "    is_active BOOLEAN,\n",
    "    deactivated_timestamp TIMESTAMP\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68d79a3c-65d0-4c41-99c5-a1add5b10e3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.table('genesis_workbench.dev_mmt_core_test.models'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14dc4e29-68d5-4352-a3d5-3b044a54123e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "model_deployments"
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS model_deployments\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE model_deployments (\n",
    "    deployment_id BIGINT,\n",
    "    deployment_name STRING,\n",
    "    deployment_description STRING,    \n",
    "    model_id BIGINT,\n",
    "    input_adapter STRING,\n",
    "    output_adapter STRING,\n",
    "    is_adapter BOOLEAN,\n",
    "    deploy_model_uc_name STRING,\n",
    "    deploy_model_uc_version STRING,\n",
    "    model_deployed_date TIMESTAMP,\n",
    "    model_deployed_by STRING,\n",
    "    model_deploy_platform STRING, -- modelserving, dcs etc\n",
    "    model_endpoint_name STRING,\n",
    "    model_invoke_url STRING,\n",
    "    is_active BOOLEAN,\n",
    "    deactivated_timestamp TIMESTAMP\n",
    ")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9235104d-3dee-47b2-9e3b-7a92ef480dd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Specify the timestamp you want to query\n",
    "# Jul 21, 2025, 11:04 AM\n",
    "# 1295466912634444\n",
    "timestamp = \"2025-07-21T11:04:00.000Z\"  # Replace with the desired timestamp\n",
    "\n",
    "# Load the table at the specified timestamp\n",
    "historical_df = spark.read.format(\"delta\").option(\"timestampAsOf\", timestamp).table(\"genesis_workbench.dev_mmt_core_test.models\")\n",
    "\n",
    "# Display the historical DataFrame\n",
    "display(historical_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd30dae6-f634-4b48-8019-167942f48111",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "save historical as current"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "\n",
    "# # Specify the timestamp you want to query\n",
    "# timestamp = \"2025-07-21T11:04:00.000Z\"  # Replace with the desired timestamp\n",
    "\n",
    "# # Load the table at the specified timestamp\n",
    "# historical_df = spark.read.format(\"delta\").option(\"timestampAsOf\", timestamp).table(\"genesis_workbench.dev_mmt_core_test.models\")\n",
    "\n",
    "# # Reassign model_id starting from 1\n",
    "# window_spec = Window.orderBy(\"model_name\")  # Replace \"model_name\" with the appropriate column to order by\n",
    "# historical_df = historical_df.withColumn(\"model_id\", row_number().over(window_spec))\n",
    "\n",
    "# # Drop the existing models table\n",
    "# spark.sql(\"DROP TABLE IF EXISTS genesis_workbench.dev_mmt_core_test.models\")\n",
    "\n",
    "# Save the historical DataFrame as the new models table\n",
    "historical_df.write.saveAsTable('genesis_workbench.dev_mmt_core_test.models')\n",
    "\n",
    "# Display the updated models table\n",
    "display(spark.table('genesis_workbench.dev_mmt_core_test.models'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "673b6bd7-86aa-4314-80c2-708d1b71bfc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.table('genesis_workbench.dev_mmt_core_test.models'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5c3f436-7095-4a05-9578-3f16dfb69a6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d38fa71-7735-4637-bba3-9ba53b9aee98",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "drop model_id"
    }
   },
   "outputs": [],
   "source": [
    "# Load the table into a DataFrame\n",
    "models_df = spark.table('genesis_workbench.dev_mmt_core_test.models')\n",
    "\n",
    "# Filter out the row where model_id is 4\n",
    "filtered_df = models_df.filter(models_df.model_id != 4)\n",
    "\n",
    "# Select all columns except the identity column\n",
    "columns_to_write = [col for col in filtered_df.columns if col != 'model_id']\n",
    "\n",
    "# Delete the existing records from the table\n",
    "spark.sql(\"DELETE FROM genesis_workbench.dev_mmt_core_test.models WHERE model_id IS NOT NULL\")\n",
    "\n",
    "# Insert the filtered DataFrame back into the table without the identity column\n",
    "filtered_df.select(columns_to_write).write.mode('append').saveAsTable('genesis_workbench.dev_mmt_core_test.models')\n",
    "\n",
    "display(spark.table('genesis_workbench.dev_mmt_core_test.models'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad01e704-4428-4de5-9102-b4051e577403",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# https://adb-830292400663869.9.azuredatabricks.net/jobs/70777228912971/runs/1035163114685297?o=830292400663869\n",
    "#deployment_id 1753091718000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "984df167-ca2f-472f-943c-845d94f7299e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "TEST"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "UPDATE genesis_workbench.dev_mmt_core_test.models\n",
    "SET is_model_deployed = false, --true,\n",
    "    deployment_ids = '' --'1753091718000'\n",
    "WHERE model_name = 'SCimilarity_Search_Nearest';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26d1de86-bb37-4979-8df4-19ba9abb72c5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "check updates"
    }
   },
   "outputs": [],
   "source": [
    "display(spark.table('genesis_workbench.dev_mmt_core_test.models'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4dc43fe2-f422-426c-a78a-97426a98a47a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "528d9b8a-9ac2-4cba-80f7-0a771ea0ca72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark.table('genesis_workbench.dev_mmt_core_test.model_deployments'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b4c80bd-2b11-4110-97ab-54ff77ff3920",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7356178690025500,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "test manually update model table where deployment succeeded but deemed failed",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
