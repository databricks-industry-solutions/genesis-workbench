resources:
  jobs:
    register_proteinmpnn:
      name: register_proteinmpnn

      email_notifications:
        on_failure:
          - ${var.current_user}

      tasks:
        #this task need 14.3 LTS L runtime
        - task_key: register_proteinmpnn_task
          job_cluster_key: job_cluster
          notebook_task:
            notebook_path: ../notebooks/01_register_proteinmpnn.py

        #this task need serverless runtime with python 3.11
        - task_key: import_protein_mpnn_task
          depends_on: 
            - task_key: register_proteinmpnn
          notebook_task:
            notebook_path: ../notebooks/02_import_model_gwb.py

      environments:
        - environment_key: default
          spec:
            client: '2'
            
      parameters:
        - name: catalog
          default: ${var.core_catalog_name}
        - name: schema
          default: ${var.core_schema_name}
        - name: model_name
          default: proteinmpnn
        - name: cache_dir
          default: ${resources.volumes.proteinmpnn_cache_dir.name}
        - name: experiment_name
          default: ${var.module_registration_experiment_name}
        - name: sql_warehouse_id
          default: ${var.sql_warehouse_id}
        - name: user_email
          default: ${var.current_user}

      job_clusters:
        - job_cluster_key: job_cluster
          new_cluster:
            num_workers: 0
            node_type_id: 'Standard_NC4as_T4_v3' 
            driver_node_type_id: 'Standard_NC4as_T4_v3' 
            spark_version: '14.3.x-gpu-ml-scala2.12'
            enable_elastic_disk: true
            data_security_mode: SINGLE_USER
            single_user_name: ${workspace.current_user.userName}
            spark_conf:
              spark.databricks.cluster.profile: singleNode
              spark.master: local[*]
            custom_tags:
              ResourceClass: SingleNode
            
            