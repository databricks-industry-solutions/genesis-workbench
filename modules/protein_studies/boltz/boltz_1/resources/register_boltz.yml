resources:
  jobs:
    register_boltz:
      name: register_boltz

      email_notifications:
        on_failure:
          - ${var.current_user}

      tasks:
        #this task need serverless runtime with python 3.11
        - task_key: register_boltz_task
          job_cluster_key: job_cluster
          notebook_task:
            notebook_path: ../notebooks/01_register_boltz.py
            
      parameters:
        - name: catalog
          default: ${var.core_catalog_name}
        - name: schema
          default: ${var.core_schema_name}
        - name: model_name
          default: boltz
        - name: cache_dir
          default: ${resources.volumes.boltz_cache_dir.name}
        - name: experiment_name
          default: ${var.module_registration_experiment_name}
        - name: sql_warehouse_id
          default: ${var.sql_warehouse_id}
        - name: user_email
          default: ${var.current_user}

      job_clusters:
        - job_cluster_key: job_cluster
          new_cluster:
            num_workers: 0
            node_type_id: 'Standard_NC4as_T4_v3' 
            driver_node_type_id: 'Standard_NC4as_T4_v3' 
            spark_version: '15.4.x-gpu-ml-scala2.12'
            enable_elastic_disk: true
            data_security_mode: SINGLE_USER
            single_user_name: ${workspace.current_user.userName}
            spark_conf:
              spark.databricks.cluster.profile: singleNode
              spark.master: local[*]
            custom_tags:
              ResourceClass: SingleNode

      tags: ${var.common_resource_tags}
            
            